{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdfsampler\n",
    "import natjoin\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPrime(n):\n",
    "    for i in range(2,int(n**0.5)+1):\n",
    "        if n%i==0:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(lower, upper, value):\n",
    "    if lower == upper:\n",
    "        return .5\n",
    "    return (float(value) - float(lower)) / (float(upper) - float(lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(entry_value, prime):\n",
    "    hash_value = 0\n",
    "    for element in str(entry_value):\n",
    "        hash_value += ord(element) % prime\n",
    "    return hash_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attrs_hash_dict(join_attrs):\n",
    "    primes = []\n",
    "    primes_needed = len(join_attrs.keys())\n",
    "    lower_bound = 31\n",
    "    upper_bound = 126\n",
    "    while len(primes) < primes_needed:\n",
    "        primes += [i for i in range(upper_bound, lower_bound+upper_bound) if isPrime(i)]\n",
    "        lower_bound = upper_bound+1\n",
    "        upper_bound += primes_needed\n",
    "\n",
    "    attrs_hash_dict = {}\n",
    "    for k, v in join_attrs.items():\n",
    "        hash_num = random.choice(primes)\n",
    "        attrs_hash_dict[k] = hash_num\n",
    "        primes.remove(hash_num)\n",
    "        \n",
    "    return attrs_hash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_indices(table_length, filtered_table_length):\n",
    "    random_indices = []\n",
    "    while len(random_indices) < filtered_table_length:\n",
    "        i = random.randint(0, table_length-1)\n",
    "        if i not in random_indices:\n",
    "            random_indices.append(i)\n",
    "    return random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdfjoin(tables, sampling_threshold):\n",
    "    if len(tables) <= 1:\n",
    "        return tables\n",
    "    else:\n",
    "        attrs = {}\n",
    "        \n",
    "        #find join attributes\n",
    "        for i in range(len(tables)):\n",
    "            table = tables[i]\n",
    "            for table_key in table[0].keys():\n",
    "                if table_key in attrs.keys(): attrs[table_key].append(i)\n",
    "                else: attrs[table_key] = [i]\n",
    "        join_attrs = {k: v for k,v in attrs.items() if len(v) > 1}\n",
    "        \n",
    "        #build dictionary of prime numbers to use when hashing each join attribute\n",
    "        attrs_hash_dict = build_attrs_hash_dict(join_attrs)\n",
    "            \n",
    "        #compute hashes of each key in join attribute dictionary\n",
    "        for k,v in attrs_hash_dict.items():\n",
    "            table_indices = join_attrs[k]\n",
    "            hash_min = hash_function(tables[table_indices[0]][0][k], v)\n",
    "            hash_max = hash_min\n",
    "            for index in table_indices:\n",
    "                table = tables[index]\n",
    "                for entry in table:\n",
    "                    hash_score = hash_function(entry[k], v)\n",
    "                    entry[str(k) + \" hash score\"] = hash_score\n",
    "                    if hash_score < hash_min:\n",
    "                        hash_min = hash_score\n",
    "                    elif hash_score > hash_max:\n",
    "                        hash_max = hash_score\n",
    "            for index in table_indices:\n",
    "                table = tables[index]\n",
    "                for entry in table:\n",
    "                    value = entry[str(k) + \" hash score\"]\n",
    "                    entry[str(k) + \" hash score\"] = normalize(hash_min, hash_max, value)\n",
    "            #attrs_hash_dict[k].append([hash_min, hash_max])\n",
    "            \n",
    "        #compute sums of all hashes i\n",
    "        for table in tables:\n",
    "            for entry in table:\n",
    "                entry[\"hash sum\"] = sum([v for k,v in entry.items() if k[-11:] == \" hash score\"])\n",
    "                delete_keys = [k for k,v in entry.items() if k[-11:] == \" hash score\"]\n",
    "                for key in delete_keys:\n",
    "                    del entry[key]\n",
    "        \n",
    "        #filter for all entries whose cdf <= sampling probability\n",
    "        filtered_tables = []\n",
    "        for i in range(len(tables)):\n",
    "            table = tables[i]\n",
    "            filtered_table = []\n",
    "            if \"hash sum\" in table[0].keys():\n",
    "                n_join_attrs = len([i for k,v in join_attrs.items() if i in v])\n",
    "                for entry in table:\n",
    "                    if cdfsampler.cdf(n_join_attrs, entry[\"hash sum\"]) <= sampling_threshold:\n",
    "                        filtered_table.append(entry)\n",
    "            if len(filtered_table) > 0:\n",
    "                filtered_tables.append(filtered_table)\n",
    "            else:\n",
    "                return []\n",
    "                \n",
    "        #select random entries from each table\n",
    "        random_tables = []\n",
    "        for i in range(len(tables)):\n",
    "            table = tables[i]\n",
    "            #print(table)\n",
    "            random_table_indices = generate_random_indices(len(table), len(filtered_tables[i]))\n",
    "            random_tables.append([table[j] for j in random_table_indices])\n",
    "        \n",
    "        random_tables_empty = False\n",
    "        for table in random_tables:\n",
    "            if len(table) == 0:\n",
    "                random_tables_empty = True\n",
    "                break\n",
    "        if random_tables_empty:\n",
    "            joined_random_tables = []\n",
    "        else:\n",
    "            joined_random_tables = natjoin.natural_join(random_tables.copy())\n",
    "    \n",
    "        \n",
    "        joined_filtered_tables = natjoin.natural_join(filtered_tables.copy())\n",
    "        print(\"filtered tables\")\n",
    "        print(joined_filtered_tables)\n",
    "        \n",
    "        print(\"\\nrandom tables\")\n",
    "        print(joined_random_tables)\n",
    "        return joined_filtered_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-38854fed13c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mexample_table_four\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"birth\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"death\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mcdfjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_table_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_table_two\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_table_three\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-84a2afaca80e>\u001b[0m in \u001b[0;36mcdfjoin\u001b[0;34m(tables, sampling_threshold)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mjoined_random_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mjoined_random_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnatjoin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatural_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_tables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/reading-research/natjoin.py\u001b[0m in \u001b[0;36mnatural_join\u001b[0;34m(tables)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassic_hash_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/reading-research/natjoin.py\u001b[0m in \u001b[0;36mclassic_hash_join\u001b[0;34m(r, s)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassic_hash_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mr_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0ms_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mcommon_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mra\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mra\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "example_table_one = [{\"name\": \"barbara lewis\", \"age\": 21, \"year\": 1957},\n",
    "                    {\"name\": \"mitski\", \"age\": 21, \"year\": 1938},\n",
    "                    {\"name\": \"julian casablancas\", \"age\": 21, \"year\": 2512},\n",
    "                    {\"name\": \"kali uchis\", \"age\": 21, \"year\": 1914},\n",
    "                    {\"name\": \"angel olsen\", \"age\": 21, \"year\": 1932},\n",
    "                    {\"name\": \"elvis presley\", \"age\": 21, \"year\": 1957}]\n",
    "\n",
    "example_table_two = [{\"name\": \"harry styles\", \"age\": 21, \"g\": \"a\"},\n",
    "                    {\"name\": \"mitski\", \"age\": 21, \"g\": \"b\"},\n",
    "                    {\"name\": \"ravyn lenae\", \"age\": 21, \"g\": \"c\"},\n",
    "                    {\"name\": \"paul simon\", \"age\": 42, \"g\": \"d\"},\n",
    "                    {\"name\": \"janis joplin\", \"age\": 27, \"g\": \"e\"},\n",
    "                    {\"name\": \"james morrison\", \"age\": 27, \"g\": \"f\"}]\n",
    "\n",
    "example_table_three = [{\"name\": \"the breeders\", \"song\": \"off you\"},\n",
    "                      {\"name\": \"mitski\", \"song\": \"nobody\"}]\n",
    "\n",
    "example_table_four = [{\"id\": \" \", \"birth\": \" \", \"death\": \" \"}]\n",
    "\n",
    "cdfjoin([example_table_one, example_table_two, example_table_three], .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
